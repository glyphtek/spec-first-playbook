# Documentation Evaluation Guide

## Overview

This guide helps you evaluate documentation generated by AI agents using our standardized evaluation tool.

## Quick Start

1. **Prepare Your Files**
   ```bash
   # Ensure you have:
   documentation/base/              # Your base documentation
   documentation/generated/         # AI-generated documentation
   documentation/evals/            # Evaluation tools
   ```

2. **Run Evaluation**
   ```bash
   # Tell your AI agent:
   "Please evaluate the generated documentation using the standardized evaluation tool
    at documentation/evals/standardized_evaluation_tool.md"
   ```

## Evaluation Process

### 1. Requirements Analysis
```bash
# Ask your AI agent:
"Please extract and classify all requirements from the base documentation."

# Expected Output:
- Core Requirements Matrix
- Extended Requirements Matrix
```

### 2. Coverage Analysis
```bash
# Ask your AI agent:
"Please analyze documentation coverage against the identified requirements."

# Expected Output:
- Documentation Mapping Matrix
- Coverage Calculations
- Gap Analysis
```

### 3. Quality Assessment
```bash
# Ask your AI agent:
"Please assess the quality of the generated documentation."

# Expected Output:
- Documentation Quality Matrix
- Technical Quality Matrix
```

### 4. Scale Alignment
```bash
# Ask your AI agent:
"Please verify scale alignment of the documentation."

# Expected Output:
- Scale Requirements Matrix
- Technology Fit Matrix
```

## What to Check

### 1. Scale Alignment
- [ ] Scale level matches PRD
- [ ] Technology choices fit scale
- [ ] Architecture aligns with scale
- [ ] Performance requirements are appropriate

### 2. Requirements Coverage
- [ ] All functional requirements covered
- [ ] All non-functional requirements addressed
- [ ] User personas and scenarios included
- [ ] Technical constraints documented

### 3. Technical Accuracy
- [ ] Architecture patterns are appropriate
- [ ] Technology choices are justified
- [ ] Security measures are adequate
- [ ] Performance considerations included

### 4. Documentation Quality
- [ ] Clear and understandable
- [ ] Properly structured
- [ ] Consistent terminology
- [ ] Complete diagrams

## Common Issues to Look For

1. **Scale Mismatches**
   - Over-engineered solutions
   - Insufficient scalability
   - Inappropriate technology choices
   - Misaligned architecture

2. **Coverage Gaps**
   - Missing requirements
   - Incomplete specifications
   - Undefined edge cases
   - Missing validations

3. **Quality Issues**
   - Unclear documentation
   - Inconsistent terminology
   - Missing diagrams
   - Poor structure

## How to Handle Issues

1. **For Any Issues Found**:
   ```bash
   # Ask your AI agent:
   "Please provide specific recommendations for [issue] following the standardized format."
   ```

2. **For Implementing Fixes**:
   ```bash
   # Ask your AI agent:
   "Please implement the recommended fixes for [issue] and update the documentation."
   ```

## Success Criteria

Your documentation is ready when:

1. **Coverage is Complete**
   - Core Requirements: ≥95%
   - Extended Requirements: ≥85%
   - No Critical Gaps
   - All Must-Fix Items Identified

2. **Quality is High**
   - Documentation Quality: ≥4/5
   - Technical Quality: ≥4/5
   - Scale Alignment: ≥90%
   - Clear Action Items

3. **Process is Complete**
   - All Steps Completed
   - All Matrices Filled
   - All Reports Generated
   - Clear Next Steps

## Next Steps

After evaluation:

1. **If Issues Found**
   - Have AI fix identified issues
   - Re-evaluate after changes
   - Document lessons learned

2. **If All Clear**
   - Proceed to implementation
   - Save evaluation results
   - Update documentation as needed

## Remember

- Always evaluate against base requirements
- Check scale appropriateness
- Verify technical accuracy
- Ensure documentation quality
- Track and resolve all issues 